{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8840aceb-a5a6-4e6e-9c66-9cd0d4414ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from platform import python_version\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "# print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a14e3c-2e2b-4496-8ac9-671eb5eedd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataset for training & testing\n",
    "movie_df = pd.read_csv (f'{os.getcwd()}/dataset.csv')\n",
    "# print(movie_df)\n",
    "movie_list = movie_df.values.tolist()\n",
    "random.shuffle(movie_list)\n",
    "shuffled_df = pd.DataFrame(movie_list, columns=movie_df.columns)\n",
    "training_dataset, test_dataset = train_test_split(shuffled_df, train_size=40000, test_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ec8f921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature extractor: BoW \n",
    "print(training_dataset)\n",
    "for i in enumerate(training_dataset['review']):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aefffa5-8724-4ca7-8589-fe80b11efe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier_agent:\n",
    "    def __init__(self):\n",
    "        print('Constructor function for classifier agent')\n",
    "        \n",
    "    def classifier():\n",
    "        z = np.dot(X,W) + b\n",
    "        \n",
    "        return 1 / (1+np.exp(z))\n",
    "        \n",
    "    def cost(self):\n",
    "        ''' Cross entropy loss: logistic loss '''\n",
    "        loss_arr = -1 * (actual_y * np.log(prob_y_predict) + ((1-actual_y) * np.log(1-prob_y_predict)))\n",
    "        overall_loss_scalar = np.sum(loss_arr) * (1/n)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d1290d-ee20-47a1-86e5-a693b726fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_extractor:\n",
    "    def __init__(self):\n",
    "        print('Constructor function for feature extractor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a482a0-dad9-4c31-8d63-236bc1a660bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_word_feature():\n",
    "    word_dict = {}\n",
    "    ''' Order is not important. Here are we expected to implement any classifier.'''\n",
    "    print('Bag of word feature')\n",
    "    \n",
    "\n",
    "def score_function():\n",
    "    ''' Here score function '''\n",
    "    print('Score function')\n",
    "\n",
    "def predict_error():\n",
    "    print(\"Error prediction\")\n",
    "\n",
    "def loss_function():\n",
    "    ''' Cross entropy loss '''\n",
    "    print(\"Loss function\")\n",
    "    loss_arr = -1 * (actual_y * np.log(prob_y_predict) + ((1-actual_y) * np.log(1-prob_y_predict)))\n",
    "    overall_loss_scalar = np.sum(loss_arr) * (1/n)\n",
    "\n",
    "def gradient():\n",
    "    ''' we can simply use pytorch autograd ? '''\n",
    "    print(\"Gradient\")\n",
    "\n",
    "def train_gd():\n",
    "    ''' here we train the data, our classifer ''' \n",
    "    print(\"Training gradient descent\")\n",
    "    # get classifier model\n",
    "    # get its predicted output\n",
    "    # measure its cost function\n",
    "    # backward propagation\n",
    "\n",
    "def train_sgd():\n",
    "    ''' here batch using ''' \n",
    "    print(\"Training stochastic gradient descent\")\n",
    "\n",
    "\n",
    "def custom_feature_extractor():\n",
    "    print(\"cUSTOM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153be935-c242-4a47-8c36-f1302a8d958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bag_of_word():\n",
    "    def __init__(self):\n",
    "        super()\n",
    "        \n",
    "    def forward():\n",
    "        print()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
