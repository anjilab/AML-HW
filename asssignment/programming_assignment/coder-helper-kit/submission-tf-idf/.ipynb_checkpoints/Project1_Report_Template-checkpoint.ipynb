{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report for Homework 1: Classifier Agent\n",
    "\n",
    "### Name: Anjila Budathoki\n",
    "### Panther ID: 002778574\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaration of Sources and Collaboration:\n",
    "\n",
    "You should declare who you worked with in this homework. Don't submit identical works, rather study together and apply it individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:  Gradient Calculations\n",
    "\n",
    "The loss function to use is the cross-entropy loss, averaged over data points.\n",
    "\n",
    "You should include your work for deriving the full gradient and stochastic gradient here.\n",
    "\n",
    "You can type equations using LATEX in markdown with, e.g. $\n",
    "e = mc^2, v = \\frac{dx}{dt}\n",
    "$\n",
    "\n",
    "$l(w, (x,y)) = - (ylog   \\hat{p}_w(x)  +  log(1 - \\hat{p}_w(x) )(1-y))$\n",
    "\n",
    "$where, \n",
    "\n",
    "\\hat{p}_w(x) =  \\dfrac{e^{w^Tx}}{1 + e^{w^Tx}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:  Gradient Descent vs Stochastic Gradient Descent\n",
    "\n",
    "Discuss what do you observe about GD and SGD from your implementation? Which one is faster in terms of number of iterations, which one is faster in terms of the wall clock time?\n",
    "\n",
    "In case of GD, There is smooth convergence, which makes sense because it takes into account of all data. \n",
    "In case of SGD, there is up-down unsmooth convergences because for gradient only 1 random sample is taken into account. \n",
    "\n",
    "Intuitively, SGD should be faster than GD, because in GD, we take all samples gradient whereas in SGD only 1 sample.\n",
    "\n",
    "Attached is the plot of error vs epoch \n",
    "<img src=\"SGD - Error vs Epoch.png\">\n",
    "<img src=\"GD - Error vs Epoch.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You can plot the learning curves, e.g., training error against epochs and wall-clock time.\n",
    "\n",
    "You can use matplotlib for plotting such figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Apply the model to your own text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructor of Extractor\n"
     ]
    }
   ],
   "source": [
    "from classifier import load_data,tokenize, compute_word_idf\n",
    "from classifier import custom_feature_extractor, classifier_agent\n",
    "import numpy as np\n",
    "\n",
    "# First load the classifier\n",
    "\n",
    "with open('data/vocab.txt') as file:\n",
    "    reading = file.readlines()\n",
    "    vocab_list = [item.strip() for item in reading]\n",
    "\n",
    "feat_map = custom_feature_extractor(vocab_list, tokenize)\n",
    "\n",
    "d = len(vocab_list)\n",
    "params = np.array([0.0 for i in range(d)])\n",
    "custom_classifier = classifier_agent(feat_map, params)\n",
    "custom_classifier.load_params_from_file('best_model.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [0] [0] [1]\n"
     ]
    }
   ],
   "source": [
    "# Try it out!\n",
    "\n",
    "my_sentence = \"This movie is amazing! Truly a masterpiece.\"\n",
    "\n",
    "my_sentence2 = \"The book is really, really good. The movie is just dreadful.\"\n",
    "my_sentence3 = \"This movie is worst, I don't like it.\"\n",
    "my_sentence4= \"Amazing, mind blowing.\"\n",
    "\n",
    "\n",
    "\n",
    "ypred = custom_classifier.predict(my_sentence,RAW_TEXT=True)\n",
    "ypred2 = custom_classifier.predict(my_sentence2,RAW_TEXT=True)\n",
    "ypred3 = custom_classifier.predict(my_sentence3,RAW_TEXT=True)\n",
    "ypred4 = custom_classifier.predict(my_sentence4,RAW_TEXT=True)\n",
    "\n",
    "\n",
    "\n",
    "print(ypred,ypred2, ypred3, ypred4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also try predicting for each word in the input so as to get a sense of how the classifier arrived at the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mw/m50sp3mn4151q1n3mldhw2fh0000gq/T/ipykernel_57922/1404405345.py:23: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  df.style.applymap(color_predictions)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c47ee_row0_col0, #T_c47ee_row0_col1, #T_c47ee_row0_col2, #T_c47ee_row0_col3, #T_c47ee_row0_col4, #T_c47ee_row0_col5, #T_c47ee_row0_col6, #T_c47ee_row0_col7, #T_c47ee_row0_col8, #T_c47ee_row0_col9, #T_c47ee_row0_col10, #T_c47ee_row1_col0, #T_c47ee_row1_col1, #T_c47ee_row1_col2, #T_c47ee_row1_col3, #T_c47ee_row1_col4, #T_c47ee_row1_col5, #T_c47ee_row1_col6, #T_c47ee_row1_col7, #T_c47ee_row1_col8, #T_c47ee_row1_col9, #T_c47ee_row1_col10 {\n",
       "  color: black;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c47ee\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c47ee_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_c47ee_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_c47ee_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_c47ee_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_c47ee_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_c47ee_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "      <th id=\"T_c47ee_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
       "      <th id=\"T_c47ee_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
       "      <th id=\"T_c47ee_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
       "      <th id=\"T_c47ee_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
       "      <th id=\"T_c47ee_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c47ee_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c47ee_row0_col0\" class=\"data row0 col0\" >the</td>\n",
       "      <td id=\"T_c47ee_row0_col1\" class=\"data row0 col1\" >book</td>\n",
       "      <td id=\"T_c47ee_row0_col2\" class=\"data row0 col2\" >is</td>\n",
       "      <td id=\"T_c47ee_row0_col3\" class=\"data row0 col3\" >really</td>\n",
       "      <td id=\"T_c47ee_row0_col4\" class=\"data row0 col4\" >really</td>\n",
       "      <td id=\"T_c47ee_row0_col5\" class=\"data row0 col5\" >good</td>\n",
       "      <td id=\"T_c47ee_row0_col6\" class=\"data row0 col6\" >the</td>\n",
       "      <td id=\"T_c47ee_row0_col7\" class=\"data row0 col7\" >movie</td>\n",
       "      <td id=\"T_c47ee_row0_col8\" class=\"data row0 col8\" >is</td>\n",
       "      <td id=\"T_c47ee_row0_col9\" class=\"data row0 col9\" >just</td>\n",
       "      <td id=\"T_c47ee_row0_col10\" class=\"data row0 col10\" >dreadful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c47ee_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c47ee_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_c47ee_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_c47ee_row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "      <td id=\"T_c47ee_row1_col3\" class=\"data row1 col3\" >1</td>\n",
       "      <td id=\"T_c47ee_row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "      <td id=\"T_c47ee_row1_col5\" class=\"data row1 col5\" >1</td>\n",
       "      <td id=\"T_c47ee_row1_col6\" class=\"data row1 col6\" >0</td>\n",
       "      <td id=\"T_c47ee_row1_col7\" class=\"data row1 col7\" >0</td>\n",
       "      <td id=\"T_c47ee_row1_col8\" class=\"data row1 col8\" >1</td>\n",
       "      <td id=\"T_c47ee_row1_col9\" class=\"data row1 col9\" >0</td>\n",
       "      <td id=\"T_c47ee_row1_col10\" class=\"data row1 col10\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x177a81710>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# function for set text color of positive\n",
    "# values in Dataframes\n",
    "def color_predictions(val):\n",
    "    eps = 0.02\n",
    "    if isinstance(val,float):\n",
    "        if val > eps:\n",
    "            color = 'blue'\n",
    "        elif val < -eps:\n",
    "            color = 'red'\n",
    "        else:\n",
    "            color = 'black'\n",
    "    else:\n",
    "        color='black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "my_sentence_list = tokenize(my_sentence2)\n",
    "ypred_per_word = custom_classifier.predict(my_sentence_list,RAW_TEXT=True,RETURN_SCORE=True)\n",
    "\n",
    "df = pd.DataFrame([my_sentence_list,ypred_per_word])\n",
    "\n",
    "df.style.applymap(color_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer the questions: \n",
    "1. Are the above results making intuitive sense and why?\n",
    "\n",
    "\n",
    "2. What are some limitation of a linear classifier with BoW features?\n",
    "\n",
    "3. what are some ideas you can come up with to overcome these limitations (i.e., what are your ideas of constructing informative features)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Document what you did for custom feature extractors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you try? What were the accuracy you got. What worked better and what not, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5:  Anything else you'd like to write about. Your instructor / TA will read them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may answer for instance:\n",
    "\n",
    "- What have you learned from the experience of working on this coding project?\n",
    "\n",
    "I learnt to implement the linear classifier, how gradient descent / SGD can be implemented. \n",
    "\n",
    "- Do you think it is easy / hard? If you find it to be hard, what is the main missing piece that you think the instructor / TA should cover in the lectures / discussion sections.\n",
    "\n",
    "It's medium for me. I was little frustrated out when my error was high. I took help from my friends (Vlad, Aditya).\n",
    "I am very grateful towards TA / instructor for providing the starter kit. It connected the dots. Thank you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
